#! /usr/bin/env python3
import argparse
import csv
import jsonpickle
import logging
import os
import subprocess
import sys
import tempfile

# Because apparently python only adds the parent directory of the running
# script to the PATH.
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__),
                                                '..')))

from binalyzer.analyzers.parallel_analyzer import ParallelAnalyzer  # noqa: E402, E501
from analyses.hash_func_discovery.hash_func_discovery_analysis import HashFuncDiscoveryAnalysis  # noqa: E402, E501

logging.getLogger('angr').setLevel(logging.CRITICAL)
logging.getLogger('cle').setLevel(logging.CRITICAL)
logging.getLogger('claripy').setLevel(logging.CRITICAL)
logging.getLogger('claripy.balancer').setLevel(logging.CRITICAL)
logging.getLogger('pyvex').setLevel(logging.CRITICAL)
logging.getLogger('pyvex.lifting.libvex').setLevel(logging.CRITICAL)
logging.getLogger('archinfo.arch').setLevel(logging.CRITICAL)

evaluation_results_dir = os.path.join(os.path.dirname(os.path.realpath(__file__)),
                                 'results')

parser = argparse.ArgumentParser(
    description='Test a set of binaries.')
parser.add_argument('--csv-out', action='store', metavar='FILE',
                    required=True, help='Test results in CSV format')
parser.add_argument('--source', action='store', metavar='DIRECTORY',
                    required=True, help='Directory of compiled .c files')
parser.add_argument('--cutoff', action='store', metavar='N', default=80,
                    help='Percent confidence cutoff')


def main():
    args = parser.parse_args()

    programs_path = args.source
    results_path = os.path.join(evaluation_results_dir, 'accuracy_evaluation_results')

    similarity_score_cutoff = int(args.cutoff)
    analysis = HashFuncDiscoveryAnalysis(similarity_score_cutoff)

    print('Running analysis...')
    par_analyzer = ParallelAnalyzer(analysis,
                                    root_dir=programs_path,
                                    elf_list_file=None,
                                    break_limit=None,
                                    remove_duplicates=False,
                                    results_path=results_path,
                                    timeout=None,
                                    nthreads=1)
    par_analyzer.run_analysis()

    compiler_hf_opt_correct = {}

    with open(args.csv_out, 'w') as csv_out:
        csv_out.write('binary,func_name,func_addr,hash_func_name,correct\n')

        with open(results_path, 'r') as fd:
            for line in fd:
                line = line.strip()
                results = jsonpickle.loads(line)
                analysis_target = results.analysis_target
                filename = analysis_target.file_name
                hf, compiler, opt = filename.split('_')
                if compiler not in compiler_hf_opt_correct:
                    compiler_hf_opt_correct[compiler] = {}
                if hf not in compiler_hf_opt_correct[compiler]:
                    compiler_hf_opt_correct[compiler][hf] = {}
                if opt not in compiler_hf_opt_correct[compiler][hf]:
                    compiler_hf_opt_correct[compiler][hf][opt] = {}

                analysis_results = results.analysis_results
                discovered_hash_funcs = analysis_results.discovered_hash_funcs
                print(filename)
                if len(discovered_hash_funcs) == 0:
                    print("  No hash funcs discovered!")
                    csv_out.write('{},{},{},{},{}\n'.format(filename,
                                                            '0',
                                                            '-1',
                                                            'notfound',
                                                            'False'))
                    compiler_hf_opt_correct[compiler][hf][opt] = False
                else:
                    for discovered_hash_func in discovered_hash_funcs:
                        func_name = discovered_hash_func.func_name
                        func_addr = discovered_hash_func.func_addr
                        hash_func_name = discovered_hash_func.hash_func_name

                        print("  {}@0x{:x} classified as {}"
                              .format(func_name,
                                      func_addr,
                                      hash_func_name))

                        # Assume that if hash_func_name is in filename, the
                        # detection is successful
                        if (hash_func_name in filename):
                            success = True
                        else:
                            success = False

                        csv_out.write('{},{},{},{},{}\n'.format(filename,
                                                                func_name,
                                                                func_addr,
                                                                hash_func_name,
                                                                success))
                        compiler_hf_opt_correct[compiler][hf][opt] = success

        print('Saved hash detection results to {} in CSV format!'.format(
            args.csv_out))

        for compiler in sorted(compiler_hf_opt_correct):
            hf_opt = compiler_hf_opt_correct[compiler]
            print("Compiler: {}".format(compiler))
            opts = set(next(iter(hf_opt.values())))
            #assert all(opts == opts_tmp for opts_tmp in hf_opt.values())
            print("{:<10}".format(''), end='')
            for opt in sorted(opts):
                print("{:<16}".format(opt), end='')
            print("")
            for hf in sorted(hf_opt):
                print("{:<10}".format(hf), end='')
                for opt in sorted(opts):
                    success = '?'
                    if opt in hf_opt[hf]:
                        success = hf_opt[hf][opt]
                    print("{:<16}".format(success), end='')
                print("")



if __name__ == "__main__":
    main()
