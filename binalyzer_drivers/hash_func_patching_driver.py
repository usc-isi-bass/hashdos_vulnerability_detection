import argparse
import sys
import os
import logging

# Because apparently python only adds the parent directory of the running script to the PATH.
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from binalyzer.analyzers.parallel_analyzer import ParallelAnalyzer
from binalyzer.util.analyzer_argument_parser import ParallelAnalyzerArgumentParser

from analyses.hash_func_patching.hash_func_patching_analysis import HashFuncPatchingAnalysis

logging.getLogger('angr').setLevel(logging.CRITICAL)
logging.getLogger('cle').setLevel(logging.CRITICAL)
logging.getLogger('claripy').setLevel(logging.CRITICAL)
logging.getLogger('claripy.balancer').setLevel(logging.CRITICAL)
logging.getLogger('pyvex').setLevel(logging.CRITICAL)
logging.getLogger('pyvex.lifting.libvex').setLevel(logging.CRITICAL)
logging.getLogger('archinfo.arch').setLevel(logging.CRITICAL)
#logging.getLogger('angr').setLevel(logging.DEBUG)
#logging.getLogger('cle').setLevel(logging.DEBUG)
#logging.getLogger('claripy').setLevel(logging.DEBUG)
#logging.getLogger('pyvex').setLevel(logging.DEBUG)
#logging.getLogger('pyvex.lifting.libvex').setLevel(logging.DEBUG)
#logging.getLogger('archinfo.arch').setLevel(logging.DEBUG)

def main():
    analyzer_argument_parser = ParallelAnalyzerArgumentParser()

    parser = argparse.ArgumentParser('Search for hash functions in binary executables.', parents=[analyzer_argument_parser])
    parser.add_argument('--score_cutoff', default=80, help='The cutoff score at which to consider a classification correct.', type=int)
    parser.add_argument('--symex_blocks', default=10, help='The number of blocks to execute symbolically after the return of the hash function', type=int)
    # Apparently this is the pythonic way to handle boolean command line arguments
    parser.add_argument('--restrict_hash_tables', default=False, help='We should only try to patch hash functions that appear to be used with hash tables.', action='store_true')
    parser.add_argument('--no-restrict_hash_tables', dest='restrict_hash_tables', help='We should not only try to patch hash functions that appear to be used with hash tables.', action='store_false')
    parser.add_argument('--disable-inline-hash-func-filters', dest='disable_inline_hash_func_filters', help='Do not use a heuristic static analysis to remove hash functions that appear to be inlined from the set of statically discovered hash functions (that we will try to patch).', default=False, action='store_true')
    parser.add_argument('--graph_order_diff_limit', default=None, help='The difference in order we allow between the detected hash function\'s CFG and the detected subgraph thereof. The default is no limit', required=False, type=int)
    parser.add_argument('--patch_dir', default='.', help='The directory in which to store the patched binaries.')
    parser.add_argument('--cached_results', type=str, required=False, help="A filename containing cached patching results.")
    parser.add_argument('--cached_hash_func_results', type=str, required=False, help="A filename containing cached hash function discovery results.")

    args = parser.parse_args()
    root_dir = args.root_dir
    elf_list = args.elf_list
    elf_list_file = args.elf_list_file
    break_limit = args.break_limit
    remove_duplicates = args.remove_duplicates
    results_path = args.results_path
    cached_results_path = args.cached_results
    cached_hash_func_results_path = args.cached_hash_func_results
    timeout = args.timeout
    nthreads = args.nthreads
    similarity_score_cutoff = args.score_cutoff
    block_symex_upperbound = args.symex_blocks
    restrict_hash_tables = args.restrict_hash_tables
    enable_static_inlined_hash_func_filters = not args.disable_inline_hash_func_filters
    graph_order_diff_limit = args.graph_order_diff_limit
    patch_dir = args.patch_dir
   
    analysis = HashFuncPatchingAnalysis(similarity_score_cutoff, block_symex_upperbound, restrict_hash_tables, graph_order_diff_limit, patch_dir, cached_results_path=cached_results_path, enable_static_inlined_hash_func_filters=enable_static_inlined_hash_func_filters, cached_hash_func_results_path=cached_hash_func_results_path)

    par_analyzer = ParallelAnalyzer(analysis, root_dir=root_dir, elf_list=elf_list, elf_list_file=elf_list_file, break_limit=break_limit, remove_duplicates=remove_duplicates, results_path=results_path, timeout=timeout, nthreads=nthreads)
    par_analyzer.run_analysis()

if __name__ == "__main__":
    main()
