import sys
import os
import angr
import claripy
import datetime

from binalyzer.analyzers.analysis import Analysis
from binalyzer.analyzers.analysis_results import AnalysisResults

import util.angr_util as angr_util
from util.milestone_logger import MilestoneLogger

from hash_patcher.hash_patch_evaluator import HashPatchEvaluator

from hash_patcher.static_patcher import StaticPatcher
from hash_patcher.hash_patch_asm_generator import HashPatchAsmGenerator

from analyses.hash_func_use.hash_func_use_analysis import HashFuncUseAnalysis
from analyses.hash_func_use.hash_func_use_analysis import HashFuncUseAnalysisResults
from analyses.hash_func_discovery.hash_func_discovery_analysis import HashFuncDiscoveryAnalysis

symb_ret_check_strs = ['a', 'ab', 'abc']
case_sensitivity_check_strs = ['Ab', 'bD', '0sY']

# Note we only use strings that are not affected by case-sensitivity
hash_vals_checks = {'bkdrhash':{'123':{847490}, '!@#$':{75289928}},
    'dekhash':{'123':{82547}, '!@#$':{5342276}},
    'pjwhash':{'123':{13395}, '!@#$':{152148}},
    'rshash':{'123':{3350397308}, '!@#$':{3818697610}},
    'jshash':{'123':{446351968}, '!@#$':{1131574688}},
    'sdbmhash':{'123':{408093746}, '!@#$':{520606112}},
    'djbhash':{'123':{193432059, 193359061}, '!@#$':{2087730413, 2085358563}}, # We allow for both DJBX33A and DJBX33X
    'elfhash':{'123':{13395}, '!@#$':{152148}},
    'aphash':{'123':{1654819135}, '!@#$':{4030010601}}
}

# Some hash algorithms cannot output all int values (like elf hash and pjw hash)
# I should probably check if any of the other hashes are like this too
hash_to_out_mod = {'bkdrhash':2**32,
    'dekhash':2**32,
    'pjwhash':2**28,
    'rshash':2**32,
    'jshash':2**32,
    'sdbmhash':2**32,
    'djbhash':2**32,
    'elfhash':2**28,
    'aphash':2**32
}

ext_mem_refs_checks = ['aa', 'abcd']

hash_patches_location = os.path.join(os.path.dirname(os.path.realpath(__file__)), '..', '..', 'hash_patches')
case_sensitive_hash_patch_asm_files = [os.path.join(hash_patches_location, 'sip_hash_func.s'),
    os.path.join(hash_patches_location, 'univ_hash_func.s')
]
case_insensitive_hash_patch_asm_files = [os.path.join(hash_patches_location, 'sip_hash_func_case_insensitive.s'),
    os.path.join(hash_patches_location, 'univ_hash_func_case_insensitive.s')
]


class HashFuncPatchingAnalysis(Analysis):

    def __init__(self, similarity_score_cutoff, block_symex_upperbound, restrict_hash_tables, patch_dir, cached_results_path: str=None, cached_hash_func_results_path: str=None):
        super().__init__(cached_results_path)
        self._similarity_score_cutoff = similarity_score_cutoff
        self._block_symex_upperbound = block_symex_upperbound
        self._patch_dir = patch_dir
        self._restrict_hash_tables = restrict_hash_tables

        self._hash_func_discovery_analysis = HashFuncDiscoveryAnalysis(self._similarity_score_cutoff, cached_results_path=cached_hash_func_results_path)
        self._hash_func_use_analysis = HashFuncUseAnalysis(self._similarity_score_cutoff, self._block_symex_upperbound)

    def results_constructor(self):
        return HashFuncPatchingAnalysisResults

    def analyze(self, analysis_target, results):
        results.log_milestone('patching analysis started')

        try:
            full_target_file_path = analysis_target.full_file_path
            target_file_name = analysis_target.file_name

            hash_func_discovery_analysis_results = self._hash_func_discovery_analysis.results_constructor()()
            hash_func_discovery_start_time = datetime.datetime.now()
            self._hash_func_discovery_analysis.get_cache_or_analyze(analysis_target, hash_func_discovery_analysis_results)
            hash_func_discovery_end_time = datetime.datetime.now()
            # Only update the start and end times if the results were not cached
            if hash_func_discovery_analysis_results.get_cached_from() is None:
                hash_func_discovery_analysis_results.set_start_time(hash_func_discovery_start_time)
                hash_func_discovery_analysis_results.set_end_time(hash_func_discovery_end_time)


            # If we only want to patch hash functions used with hash tables
            # We filter out all hash other functions
            hash_func_use_analysis_results = None
            if self._restrict_hash_tables:
                hash_func_use_analysis_results = self._hash_func_use_analysis.results_constructor()()
                hash_func_use_start_time = datetime.datetime.now()
                self._hash_func_use_analysis.get_cache_or_analyze(analysis_target, hash_func_use_analysis_results)
                hash_func_use_end_time = datetime.datetime.now()
                # Only update the start and end times if the results were not cached
                if hash_func_use_analysis_results.get_cached_from() is None:
                    hash_func_use_analysis_results.set_start_time(hash_func_use_start_time)
                    hash_func_use_analysis_results.set_end_time(hash_func_use_end_time)
                hash_func_uses = hash_func_use_analysis_results.hash_func_uses
                # Filter in hash functions that appear to be used with hash tables
                hash_funcs_to_patch = set()
                # Go through all the hash function uses (hash function + call site + reads/writes/seeks)
                for hash_func_use in hash_func_uses:
                    # If the hash function is used, add it to a set
                    # (We need to use a set, because one hash function can have many call sites)
                    if self.hash_func_is_used(hash_func_use):
                        hash_func = hash_func_use.discovered_hash_func
                        hash_funcs_to_patch.add(hash_func)
            else:
                hash_funcs_to_patch = hash_func_discovery_analysis_results.discovered_hash_funcs
            results.log_milestone('completed: obtain hash funcs to patch')
            assert hash_func_discovery_analysis_results is not None, "Logic error: by now we need to know what hash functions to patch"
            # patching only hash functions used with hash tables implies that by now we should have the hash func use analysis results
            assert (not self._restrict_hash_tables) or (hash_func_use_analysis_results is not None), "Logic error: we want to restrict to patching hash table functions, but we should have had the analysis results by now"
            results.set_hash_funcs_to_patch(hash_func_discovery_analysis_results)
            results.set_hash_func_use_analysis_results(hash_func_use_analysis_results)
            if len(hash_funcs_to_patch) <= 0:
                return
            proj = angr.Project(full_target_file_path, auto_load_libs=False)
            cfg_fast = proj.analyses.CFGFast()


            results.log_milestone('started patching hash funcs')
            # For every used hash function patch it
            for discovered_hash_func in hash_funcs_to_patch:
                hash_func_patch_details = HashFuncPatchDetails(discovered_hash_func)
                idx = results.add_hash_func_patch_details(hash_func_patch_details)
                func_addr = discovered_hash_func.func_addr

                patched_elf_file_name = target_file_name + "_patch_0x{:x}".format(func_addr)
                patched_elf_file_path = os.path.join(self._patch_dir, patched_elf_file_name)
                hash_func = cfg_fast.functions.function(addr=func_addr)
                hash_alg_name = discovered_hash_func.hash_func_name

                if hash_func is None:
                    node = cfg_fast.model.get_any_node(func_addr, anyaddr=True)
                    if node is not None:
                        hash_func = cfg_fast.functions.function(node.function_address)
                if hash_func is None:
                    hash_func_patch_details.add_err("Could not find function at addr 0x{:x} (aborting patching).".format(func_addr))
                    results.update_hash_func_patch_details(idx, hash_func_patch_details)
                    continue
                hash_func_patch_details.log_milestone('patch evaluation started')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                # We start with checks on the original hash function
                hash_patch_evaluator_sig1 = HashPatchEvaluator(full_target_file_path, func_addr, 'sig1', vuln_proj=proj)
                hash_patch_evaluator_sig2 = HashPatchEvaluator(full_target_file_path, func_addr, 'sig2', vuln_proj=proj)


                # Check the signature
                sig1_check = hash_patch_evaluator_sig1.check_signature(check_original=True)
                sig2_check = hash_patch_evaluator_sig2.check_signature(check_original=True)

                hash_func_patch_details.orig_hash_sig1 = sig1_check
                hash_func_patch_details.orig_hash_sig2 = sig2_check
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                if not (sig1_check or sig2_check):
                    hash_func_patch_details.add_err("Could not find a signature that works (aborting patching).")
                    results.update_hash_func_patch_details(idx, hash_func_patch_details)
                    continue

                # If both are true, we can probably pick either right?
                if sig1_check:
                    hash_patch_evaluator = hash_patch_evaluator_sig1
                else:
                    hash_patch_evaluator = hash_patch_evaluator_sig2
                hash_func_patch_details.log_milestone('completed: signature detection')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)


                # Check the hash values
                symbolic_ret_irregularities = hash_patch_evaluator.check_symb_ret(symb_ret_check_strs, check_original=True)
                hash_func_patch_details.orig_hash_symb_ret_irregularities = symbolic_ret_irregularities
                results.update_hash_func_patch_details(idx, hash_func_patch_details)
                str_to_hashval_map = hash_vals_checks[hash_alg_name]
                # XXX This causes a problem for hash functions that cast down their return
                hash_val_irregularities = hash_patch_evaluator.check_hash_vals(hash_alg_name, str_to_hashval_map, check_original=True)
                hash_func_patch_details.orig_hash_val_irregularities = hash_val_irregularities
                hash_func_patch_details.log_milestone('completed: orig hash values check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                # Check for case sensitivity
                case_sensitivity = hash_patch_evaluator.check_case_sensitivity(case_sensitivity_check_strs, check_original=True)
                hash_func_patch_details.orig_case_sensitive = case_sensitivity
                hash_func_patch_details.log_milestone('completed: orig case sensitivity check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)


                # Check the external memory references (outside the stack-frame of the hash function)
                ext_mem_refs_irregularities = hash_patch_evaluator.check_ext_mem_refs(ext_mem_refs_checks, check_original=True)
                hash_func_patch_details.orig_hash_ext_mem_ref_irregularities = ext_mem_refs_irregularities
                hash_func_patch_details.log_milestone('completed: orig ext mem refs check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)


                # Now do the patch
                if case_sensitivity:
                    hash_patch_asm_files = case_sensitive_hash_patch_asm_files
                else:
                    hash_patch_asm_files = case_insensitive_hash_patch_asm_files
                if sig1_check:
                    len_in_reg = 'rsi'
                else:
                    len_in_reg = None
                # Get a value to mod the output of the replacement hash with
                out_mod = hash_to_out_mod[hash_alg_name]

                hash_func_patch_details.patch_insert_successes = {}
                results.update_hash_func_patch_details(idx, hash_func_patch_details)
                for hash_patch_asm_file in hash_patch_asm_files:
                    hash_func_patch_details.patch_insert_successes[os.path.basename(hash_patch_asm_file)] = False
                    results.update_hash_func_patch_details(idx, hash_func_patch_details)
                    hpag = HashPatchAsmGenerator(proj, asm_file=hash_patch_asm_file, buf_in_reg='rdi', len_in_reg=len_in_reg, out_mod=out_mod)
                    hash_patch_asm_code = hpag.get_asm_code()
                    patcher = StaticPatcher(full_target_file_path)
                    patch_success = patcher.hook_func(hash_func.addr, hash_patch_asm_code, patch_call_sites=False, patch_orig_func=True)


                    if patch_success:
                        patcher.apply_patches(patched_elf_file_path)
                        hash_func_patch_details.patch_insert_successes[os.path.basename(hash_patch_asm_file)] = True
                        results.update_hash_func_patch_details(idx, hash_func_patch_details)
                        break
                if not patch_success:
                    hash_func_patch_details.add_err("Could not add replacement hash function to binary (aborting patching).")
                    results.update_hash_func_patch_details(idx, hash_func_patch_details)
                    continue
                hash_func_patch_details.log_milestone('completed: patch inserted replacement hash func')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                # Now check the patched hash function
                hash_patch_evaluator.set_patch(patched_elf_file_path)

                # Case sensitivity
                patch_case_sensitivity = hash_patch_evaluator.check_case_sensitivity(case_sensitivity_check_strs, check_original=False)
                hash_func_patch_details.patch_case_sensitive = patch_case_sensitivity
                hash_func_patch_details.log_milestone('completed: patch case sensitivity check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                # Check the external memory references (outside the stack-frame of the hash function)
                ext_mem_refs_irregularities = hash_patch_evaluator.check_ext_mem_refs(ext_mem_refs_checks, check_original=False) # We need to use the same concrete buffers so that we know what memory references to expect
                hash_func_patch_details.patch_hash_ext_mem_ref_irregularities = ext_mem_refs_irregularities
                hash_func_patch_details.log_milestone('completed: patch ext mem refs check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)


                # Check that hash values we get for the patched hash function have preimages for the original hash function
                range_irregularities = hash_patch_evaluator.check_hash_vals_range(conc_bufs=['aa', 'AbC'])
                hash_func_patch_details.range_irregularities = range_irregularities
                hash_func_patch_details.log_milestone('completed: patch hash val range check')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)

                hash_func_patch_details.log_milestone('completed: patch evaluation finished')
                results.update_hash_func_patch_details(idx, hash_func_patch_details)
            results.log_milestone('finished patching hash funcs')



        except Exception as e:
            results.add_err(str(e))

    def hash_func_is_used(self, hash_func_use):
        hash_func_reads = hash_func_use.reads
        hash_func_writes = hash_func_use.writes
        hash_func_seeks = hash_func_use.seeks

        return len(hash_func_reads) > 0 or len(hash_func_writes) > 0 or len(hash_func_seeks) > 0

class HashFuncPatchingAnalysisResults(AnalysisResults,MilestoneLogger):

    def __init__(self):
        MilestoneLogger.__init__(self)
        AnalysisResults.__init__(self)
        self.hash_funcs_to_patch = None
        self.hash_func_use_analysis_results = None
        self.hash_func_patch_details_list = []
        self.errs = []

    def set_hash_funcs_to_patch(self, value):
        self.hash_funcs_to_patch = value

    def set_hash_func_use_analysis_results(self, value):
        self.hash_func_use_analysis_results = value

    def add_hash_func_patch_details(self, hash_func_patch_details):
        self.hash_func_patch_details_list.append(hash_func_patch_details)
        return len(self.hash_func_patch_details_list) - 1

    def update_hash_func_patch_details(self, i, hash_func_patch_details):
        self.hash_func_patch_details_list[i] = hash_func_patch_details


    def get_tracked_events(self):
        tracked_events = {}
        tracked_events['errs'] = len(self.errs)
        tracked_events['timeouts'] = len([e for e in self.errs if 'timeout' in e])

        return tracked_events

    def copy_from_inner(self, other_analysis_results):
        self.set_hash_funcs_to_patch(other_analysis_results.hash_funcs_to_patch)
        self.set_hash_func_use_analysis_results(other_analysis_results.hash_func_use_analysis_results)
        for hash_func_patch_details in other_analysis_results.hash_func_patch_details_list:
            self.add_hash_func_patch_details(hash_func_patch_details)
        for milestone_timestamp in other_analysis_results.milestone_timestamps:
            milestone_msg, milestone_time = milestone_timestamp
            self.add_milestone(milestone_msg, milestone_time)
        for err in other_analysis_results.errs:
            self.add_err(err)

class HashFuncPatchDetails(MilestoneLogger):

    # patch_target should be  discovered hash func
    def __init__(self, patch_target):
        MilestoneLogger.__init__(self)
        self.patch_target = patch_target

        self.orig_hash_symb_ret_irregularities = None
        self.orig_case_sensitive = None
        self.orig_hash_val_irregularities = None
        self.orig_hash_sig1 = None
        self.orig_hash_sig2 = None
        self.orig_hash_ext_mem_ref_irregularities = None

        self.patch_insert_successes = None

        self.patch_case_sensitive = None
        self.patch_hash_ext_mem_ref_irregularities = None

        self.range_irregularities = None

        self.milestone_timestamps = []

        self.errs = []

    def add_err(self, err):
        self.errs.append(err)

    def any_irregularities(self):
        if self.orig_hash_symb_ret_irregularities is None or len(self.orig_hash_symb_ret_irregularities) > 0:
            return True
        if self.orig_hash_val_irregularities is None or len(self.orig_hash_val_irregularities) > 0:
            return True
        if self.orig_hash_ext_mem_ref_irregularities is None or len(self.orig_hash_ext_mem_ref_irregularities) > 0:
            return True
        if self.patch_hash_ext_mem_ref_irregularities is None or len(self.patch_hash_ext_mem_ref_irregularities) > 0:
            return True
        if self.range_irregularities is None or len(self.range_irregularities) > 0:
            return True
        return False


